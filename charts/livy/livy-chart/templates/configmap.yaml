apiVersion: v1
kind: ConfigMap
metadata:
  name: {{ include "livy-chart.configmapName" . }}
  {{- if .Values.ownerReference.overRide }}
  {{- with .Values.ownerReference.ownerReferences }}
  ownerReferences: {{- toYaml . | nindent 2 }}
  {{- end }}
  {{- end }}
  labels:
  {{- include "livy-chart.labels" . | nindent 4 }}
data:
  livy-client.conf: |
    # Environment variables here would be replaced by its values

    livy.rsc.server.connect.timeout = 600s
    livy.rsc.client.connect.timeout = 600s
  livy.conf: |
    # Environment variables here would be replaced by its values
    livy.repl.enable-hive-context = true
    livy.repl.jars = local:///opt/mapr/livy/repl-jars/commons-codec,local:///opt/mapr/livy/repl-jars/livy-core_2.12.jar,local:///opt/mapr/livy/repl-jars/livy-repl_2.12.jar
    livy.rsc.jars = local:///opt/mapr/livy/rsc-jars/livy-api.jar,local:///opt/mapr/livy/rsc-jars/livy-rsc.jar,local:///opt/mapr/livy/rsc-jars/minlog.jar,local:///opt/mapr/livy/rsc-jars/netty-all.jar,local:///opt/mapr/livy/rsc-jars/objenesis.jar,local:///opt/mapr/livy/rsc-jars/reflectasm.jar
    livy.rsc.pyspark.archives = local:///opt/mapr/spark/pyspark-archives/pyspark.zip,local:///opt/mapr/spark/pyspark-archives/py4j-src.zip
    {{- if eq .Values.sessionRecovery.kind "zookeeper" }}
    livy.server.recovery.mode = recovery
    livy.server.recovery.state-store = zookeeper
    livy.server.recovery.state-store.url = ${MAPR_ZK_QUORUM}
    livy.server.recovery.zk-state-store.key-prefix = livy/${POD_NAMESPACE}-${HOSTNAME}
    {{- else if eq .Values.sessionRecovery.kind "pvc" }}
    livy.server.recovery.mode = recovery
    livy.server.recovery.state-store = filesystem
    livy.server.recovery.state-store.url = file:///opt/mapr/livy/livy-{{ include "livy-chart.livyVersion" . }}/session-store
    {{- else }}
    livy.server.recovery.mode = off
    {{- end }}
    {{- if .Values.livySsl.enable }}
      {{- if and .Values.livySsl.sslSecretName .Values.livySsl.secretMountPath }}
    livy.ssl.enable = true
      {{- else }}
    livy.ssl.enable = auto
      {{- end }}
    {{- else }}
    livy.ssl.enable = false
    {{- end }}
    livy.server.kubernetes.createUserSecret = true
    livy.server.kubernetes.userSecretPattern = {{ include "livy-chart.userSecretPattern" . }}
    livy.rsc.client.get-driver-ip-from-connection = false
    {{- if .Values.autosetNamespace.enable }}
    livy.server.kubernetes.namespacePattern = {{ .Values.autosetNamespace.namespacePattern }}
    livy.server.kubernetes.driverSaPattern = {{ .Values.autosetNamespace.driverSaPattern }}
    livy.server.kubernetes.executorSaPattern = {{ .Values.autosetNamespace.executorSaPattern }}
    {{- end }}

  spark-blacklist.conf: |
    {{- if .Values.autosetNamespace.enable }}
    spark.kubernetes.namespace
    spark.kubernetes.authenticate.driver.serviceAccountName
    spark.kubernetes.authenticate.driver.serviceAccountName
    {{- end }}

  post-startup.sh: |
    #!/usr/bin/env bash
  pre-startup.sh: |
    #!/usr/bin/env bash
  spark-defaults.conf: |
    # Environment variables here would be replaced by its values

    spark.kubernetes.container.image.pullSecrets imagepull
    spark.kubernetes.container.image.pullPolicy IfNotPresent
    spark.kubernetes.driver.request.cores 1
    spark.kubernetes.driver.limit.cores 1
    spark.kubernetes.executor.request.cores 1
    spark.kubernetes.executor.limit.cores 1

    spark.kubernetes.container.image {{ include "livy-chart.fullDeImage" . }}
    {{- if .Values.sparkHistoryServer.integrate }}
    {{- if .Values.sparkHistoryServer.pvcName }}
    spark.kubernetes.driver.volumes.persistentVolumeClaim.sparkhs-eventlog-storage.options.claimName {{ .Values.sparkHistoryServer.pvcName }}
    spark.kubernetes.driver.volumes.persistentVolumeClaim.sparkhs-eventlog-storage.mount.path {{ .Values.sparkHistoryServer.eventsDir }}
    {{- end }}
    spark.eventLog.dir {{ .Values.sparkHistoryServer.eventsDir }}
    spark.eventLog.enabled true
    {{- else }}
    spark.eventLog.enabled false
    {{- end }}

    spark.ssl.enabled false

    {{- if .Values.tenantIsUnsecure }}
    spark.hadoop.fs.default.name file:///
    {{- else }}
    spark.sql.warehouse.dir maprfs:///apps/{{ .Release.Namespace }}/spark-warehouse
    {{- end }}
