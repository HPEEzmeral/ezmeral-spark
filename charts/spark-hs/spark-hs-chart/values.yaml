# Default values for spark-hs chart.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

# replicaCount -- Desired number of pods, leaderElection will be enabled
# if this is greater than 1
replicaCount: 1

image:
  # -- Image repository
  baseRepository: gcr.io/mapr-252711
  # -- Image Name for 3.5.0 version
  imageName: spark-hs-3.5.1
  # -- Image pull policy
  pullPolicy: Always
  # -- Overrides the image tag whose default is the chart appVersion.
  # -- Image tag
  tag: "202411190216R"

# -- Whether to create a default pull secret
createDefaultPullSecret: false
# -- Default pull secret name to be created, update it in imagePullSecrets's name
defaultPullSecret: imagepull

# -- Image pull secrets, name set to imagepull, change here if chart is creating defaultPullSecret
imagePullSecrets:
  - name: imagepull

# -- String to partially override `spark-operator.fullname` template (will maintain the release name)
nameOverride: ""

# -- String to override release name
fullnameOverride: ""

# -- restart policy
restartPolicy: "Always"

automountServiceAccountToken: true

progressDeadlineSeconds: 600

revisionHistoryLimit: 10

#sparkVersion for the applications
sparkVersion: spark-3.5.1

#HPE tenant namespace info
tenantIsUnsecure: false

# set this only when tenant is unsecure and custom SSL is present
useCustomSSL: false

#HPE tenant namespace service account
serviceAccount:
  # Specifies whether a service account should be created
  # Default Service account is hpe-{{ ReleaseNamespace }}, which is created by Tenant operator.
  create: false
  # Annotations to add to the service account
  annotations: {}
  # The name of the service account to use. Please only use the tenant Service Account
  # This name is used only when create ServiceAccount option is set to true.
  name: ""

#Create RBAC for the Service Account
rbac:
  #RBAC is created only when this flag is true and ServiceAccount.create is also true
  create: false

#set this only when configuring sssd
nativeSSSD: true

#enable ssh
ssh:
  enableMount: true

#enable this to include node affinity
nodeAffinity: true

podSecurityContext: {}

securityContext:
  capabilities:
    add:
     - SYS_NICE
     - SYS_RESOURCE
  runAsGroup: 5000
  runAsUser: 5000
  # Pod needs to run as privileged on OpenShift environment to use hostPath mounts
  privileged: true

#service info
service:
  type: NodePort

#container ports
ports:
  sshPort: 22
  httpPort: "18080"
  httpsPort: "18480"

# resources -- Pod resource requests and limits
resources:
   limits:
     cpu: 2000m
     memory: 2Gi
   requests:
     cpu: 1000m
     memory: 1Gi

#owner Reference
ownerReference:
  overRide: false
  ownerReferences: {}

# Add custom labels to spark history server pod
customLabels:

eventlogstorage:
  kind: maprfs #supported types are pvc, maprfs and s3
  ##Uncomment these parameters for using s3 as events log storage
#  s3path: "/abc"
#  s3Endpoint: "abc"
#  s3AccessKey: "qwecr"
#  s3SecretKey: "qwwd"
  ## s3 configs end here
  ##Uncomment these parameters for using pvc as events log storage
#  pvcName: "" #add an existing PVC if you do not want to create an existing PVC
#  ## If defined, storageClass: <storageClass> chart will use the storage class provided
#  ## If set to "-", storageClass: "", which disables dynamic provisioning
#  ## If undefined (the default) or set to null, no storageClass spec is set. Default storageClass will be used.
## storageClass: "-"
#  storageSize: 5Gi
#  ## Add specs related to PV volume plugin to create a PV for the PVC. If volumePluginSpec is
#  ## not set any available PV would be used for the PVC
##  volumePluginSpec: {}
  ## PVC configs end here

# Data provided in "sparkExtraConfigs" will be added to spark configuration through a K8S secret
# Useful to pass secure config options to spark, e.g. S3 credentials or ACL configurations
# Note: For EZAF envs, this value is set via corresponding 'start.sh' script because it requires reading local env variables
# at install time. Helm charts do not support that (https://github.com/helm/helm/issues/10026)
sparkExtraConfigs: |
  spark.history.ui.acls.enable true
  spark.history.ui.admin.acls mapr
  spark.history.fs.cleaner.enabled true
  spark.history.fs.cleaner.maxAge 12h
  spark.history.fs.cleaner.interval 6h
  spark.eventLog.rolling.enabled true
  spark.eventLog.rolling.maxFileSize 128m
  spark.history.fs.eventLog.rolling.maxFilesToRetain 2
#  spark.ssl.historyServer.enabled           true
#  spark.ssl.historyServer.keyStore          /var/spark/ssl_keystore
#  spark.ssl.historyServer.keyStorePassword  examplepass
#  spark.ssl.historyServer.keyPassword       examplepass
#  spark.ssl.historyServer.protocol          TLSv1.2
#  spark.ssl.historyServer.keyStoreType      PKCS12

# Space separated Java options for Spark HS (Will be added to SPARK_HISTORY_OPTS in spark-env.sh)
#HSJavaOpts: -Dx=y

# Alpha feature
sparkSsl:
  enable: true
  useCustomKeystore: false
  sslSecretName: "spark-hs-ssl-secret"
  secretMountPath: /var/spark

# istio-related settings
istio:
  # Whether to enable istio sidecar injection on spark-hs pods
  enable: false
  # Istio virtual service settings
  virtualService:
    create: false
    endpoint: ""
    istioGateway: ""
    prefix: /
  # Istio authorization policy settings.
  # If enabled - an authpolicy with 'action':'CUSTOM' will be created for virtualService.endpoint
  authPolicy:
    create: false
    provider: ""
