# Default values for spark-hs chart.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

# replicaCount -- Desired number of pods, leaderElection will be enabled
# if this is greater than 1
replicaCount: 1

image:
  # -- Image repository
  baseRepository: gcr.io/mapr-252711
  # -- Image Name for 3.2.0 version
  imageName: spark-hs-3.2.0
  # -- Image name for 2.4.7 version
  #  imageName: spark-hs-2.4.7
  # -- Image pull policy
  pullPolicy: Always
  # -- Overrides the image tag whose default is the chart appVersion.
  # -- Image tag for 3.2.0 version
  tag: "202206300317R"
  # -- Image tag for 2.4.7 version
  # tag: "202206300317R"

# -- Image pull secrets
imagePullSecrets:
  - name: imagepull

createDefaultPullSecret: false
defaultPullSecret: imagepull

# -- String to partially override `spark-operator.fullname` template (will maintain the release name)
nameOverride: ""

# -- String to override release name
fullnameOverride: ""

# -- restart policy
restartPolicy: "Always"

automountServiceAccountToken: true

progressDeadlineSeconds: 600

revisionHistoryLimit: 10

#sparkVersion for the applications
sparkVersion: spark-3.2.0
## spark version for 2.4.7
#sparkVersion: spark-2.4.7

#HPE tenant namespace info
tenantIsUnsecure: false

# set this only when tenant is unsecure and custom SSL is present
useCustomSSL: false

#HPE tenant namespace service account
serviceAccount:
  # Specifies whether a service account should be created
  # Default Service account is hpe-{{ ReleaseNamespace }}, which is created by Tenant operator.
  create: false
  # Annotations to add to the service account
  annotations: {}
  # The name of the service account to use. Please only use the tenant Service Account
  # This name is used only when create ServiceAccount option is set to true.
  name: ""

#Create RBAC for the Service Account
rbac:
  #RBAC is created only when this flag is true and ServiceAccount.create is also true
  create: false

podSecurityContext: {}

#service info
service:
  type: NodePort

#container ports
ports:
  sshPort: 22
  httpPort: "18080"
  httpsPort: "18480"

# resources -- Pod resource requests and limits
resources:
   limits:
     cpu: 8000m
     memory: 8Gi
     ephemeral-storage: 30Gi
   requests:
     cpu: 2000m
     memory: 8Gi
     ephemeral-storage: 30Gi

#owner Reference
ownerReference:
  overRide: false
  ownerReferences: {}

eventlogstorage:
  kind: maprfs #supported types are pvc, maprfs and s3
  ##Uncomment these parameters for using s3 as events log storage
#  s3path: "/abc"
#  s3Endpoint: "abc"
#  s3AccessKey: "qwecr"
#  s3SecretKey: "qwwd"
  ## s3 configs end here
  ##Uncomment these parameters for using pvc as events log storage
#  pvcName: "" #add an existing PVC if you do not want to create an existing PVC
#  ## If defined, storageClass: <storageClass> chart will use the storage class provided
#  ## If set to "-", storageClass: "", which disables dynamic provisioning
#  ## If undefined (the default) or set to null, no storageClass spec is set. Default storageClass will be used.
## storageClass: "-"
#  storageSize: 5Gi
#  ## Add specs related to PV volume plugin to create a PV for the PVC. If volumePluginSpec is
#  ## not set any available PV would be used for the PVC
##  volumePluginSpec: {}
  ## PVC configs end here

# activate daemonize mode for hs
daemonize: true

# Alpha feature
# Data provided in "sparkExtraConfigs" will be added to spark configuration through a K8S secret
# Useful to pass secure config options to spark, e.g. S3 credentials
sparkExtraConfigs: |
#  spark.ssl.historyServer.enabled           true
#  spark.ssl.historyServer.keyStore          /var/spark/ssl_keystore
#  spark.ssl.historyServer.keyStorePassword  examplepass
#  spark.ssl.historyServer.keyPassword       examplepass
#  spark.ssl.historyServer.protocol          TLSv1.2
#  spark.ssl.historyServer.keyStoreType      PKCS12

# Alpha feature
sparkSsl:
  useCustomKeystore: false
  sslSecretName: "spark-hs-ssl-secret"
  secretMountPath: /var/spark

# Space separated Java options for Spark HS (Will be added to SPARK_HISTORY_OPTS in spark-env.sh)
#HSJavaOpts: -Dx=y
