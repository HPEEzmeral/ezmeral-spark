# Default values for spark-hs-chart.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

replicaCount: 1

image:
  repository: gcr.io/mapr-252711/apache-spark-hs-3.1.1
  tag: "202107131409"
  pullPolicy: IfNotPresent

createDefaultPullSecret: true
defaultPullSecret: imagepull

nameOverride: ""
fullnameOverride: ""
service:
  type: NodePort
  # nodePort: 32000
  port:
    number: 18080
    name: http-historyport
  annotations: {}

rbac:
  create: true

serviceAccount:
  create: true
  name: history-server-sa

ownerReference:
  overRide: false
  ownerReferences: {}

environment:
# Note: do not configure Spark history events directory using SPARK_HISTORY_OPTS. It will be
# configured by this chart based on the values in "pvc" or "hdfs" attribute.
# SPARK_HISTORY_OPTS: ...
# SPARK_DAEMON_MEMORY: 1g
# SPARK_DAEMON_JAVA_OPTS: ...
# SPARK_DAEMON_CLASSPATH: ...
# SPARK_PUBLIC_DNS: ...

podAnnotations: {}

resources: {}
  # We usually recommend not to specify default resources and to leave this as a conscious
  # choice for the user. This also increases chances charts run on environments with little
  # resources, such as Minikube. If you do want to specify resources, uncomment the following
  # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
  #
  # To let the application start up quickly give it a big limit
  # limits:
  #  cpu: 1000m
  #  memory: 1Gi
  # requests:
  #  cpu: 100m
#  memory: 512Mi

pvc:
  # to use a file system path for Spark events dir, set 'enablePVC' to true and mention the
  # name of an already created persistent volume claim in existingClaimName.
  # The volume will be mounted on /data in the pod
  enablePVC: true
  existingClaimName: spark-data-pvc #example PVC. update the PVC
  eventsDir: "/"

hdfs:
  hdfsSiteConfigMap: hdfs-site
  coreSiteConfigMap: core-site
  logDirectory: hdfs://hdfs/history/
  HADOOP_CONF_DIR: /etc/hadoop

imagePullSecrets: []

nodeSelector: {}

tolerations: []

affinity: {}
