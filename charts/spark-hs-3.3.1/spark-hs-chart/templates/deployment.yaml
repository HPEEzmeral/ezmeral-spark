apiVersion: apps/v1
kind: Deployment
metadata:
  name: {{ include "spark-hs-chart.fullname" . }}
  {{- if .Values.ownerReference.overRide }}
  {{- with  .Values.ownerReference.ownerReferences }}
  ownerReferences: {{- toYaml . | nindent 2 }}
  {{- end }}
  {{- end }}
  labels:
    app.kubernetes.io/name: {{ include "spark-hs-chart.name" . }}
    helm.sh/chart: {{ include "spark-hs-chart.chart" . }}
    app.kubernetes.io/instance: {{ .Release.Name }}
spec:
  progressDeadlineSeconds: {{ .Values.progressDeadlineSeconds }}
  replicas: {{ .Values.replicaCount }}
  revisionHistoryLimit: {{ .Values.revisionHistoryLimit }}
  selector:
    matchLabels:
      app.kubernetes.io/name: {{ include "spark-hs-chart.name" . }}
      app.kubernetes.io/instance: {{ .Release.Name }}
  strategy:
    rollingUpdate:
      maxSurge: 25%
      maxUnavailable: 25%
    type: RollingUpdate
  template:
    metadata:
      labels:
       app.kubernetes.io/name: {{ include "spark-hs-chart.name" . }}
       app.kubernetes.io/instance: {{ .Release.Name }}
    spec:
      serviceAccountName: {{ include "spark-hs-chart.serviceAccountName" . }}
      imagePullSecrets:
        {{- include "spark-hs-chart.imagepullSecrets" . | indent 8 }}
      containers:
        - name: {{ .Chart.Name }}
          image: "{{ .Values.image.repository }}:{{ .Values.image.tag }}"
          imagePullPolicy: {{ .Values.image.pullPolicy }}
          env:
            - name: HADOOP_CONF_DIR
              value: {{ .Values.hdfs.HADOOP_CONF_DIR }}
            - name: SPARK_NO_DAEMONIZE
              value: "true"
            - name: SPARK_USER
              value: "185"
          ports:
            - name: historyport
              containerPort: 18080
              protocol: TCP
          {{- with .Values.resources }}
          resources:
            {{- toYaml . | nindent 12 }}
          {{- end }}
          {{- if .Values.pvc.enablePVC }}
          args:
            - "--pvc"
            - "--events-dir"
            - "{{ .Values.pvc.eventsDir }}"
          {{- else if .Values.s3.enableS3 }}
          args:
            - "--s3"
            - "--events-dir"
            - "{{ .Values.s3.eventsDir }}"
          {{- end }}
          envFrom:
            - configMapRef:
                name: {{ include "spark-hs-chart.fullname" . }}
          livenessProbe:
            tcpSocket:
              port: {{ .Values.ports.httpPort }}
            initialDelaySeconds: 5
            periodSeconds: 10
          readinessProbe:
            tcpSocket:
              port: {{ .Values.ports.httpPort }}
            initialDelaySeconds: 5
            periodSeconds: 10
          startupProbe:
            tcpSocket:
              port: {{ .Values.ports.httpPort }}
            initialDelaySeconds: 30
            periodSeconds: 10
            failureThreshold: 30
          {{- if .Values.pvc.enablePVC }}
          volumeMounts:
            - name: sparkhs-eventlog-storage
              mountPath: {{ .Values.pvc.eventsDir }}
          {{- else if eq .Values.s3.enableS3 false }}
          volumeMounts:
            - name: core-site
              mountPath: /etc/hadoop/core-site.xml
              subPath: core-site.xml
            - name: hdfs-site
              mountPath: /etc/hadoop/hdfs-site.xml
              subPath: hdfs-site.xml
          {{- end }}
      {{- if .Values.pvc.enablePVC }}
      volumes:
        - name: sparkhs-eventlog-storage
          persistentVolumeClaim:
            claimName: {{ include "spark-hs-chart.pvcName" .  }}
      {{- else }}
      volumes:
        - name: hdfs-site
          configMap:
            name: {{ .Values.hdfs.hdfsSiteConfigMap }}
        - name: core-site
          configMap:
            name: {{ .Values.hdfs.coreSiteConfigMap }}
      {{- end }}
      {{- with .Values.nodeSelector }}
      nodeSelector:
      {{- toYaml . | nindent 8 }}
      {{- end }}
      {{- with .Values.affinity }}
      affinity:
      {{- toYaml . | nindent 8 }}
      {{- end }}
      {{- with .Values.tolerations }}
      tolerations:
      {{- toYaml . | nindent 8 }}
      {{- end }}
