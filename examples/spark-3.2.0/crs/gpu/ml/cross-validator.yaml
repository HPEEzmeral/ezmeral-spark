apiVersion: "sparkoperator.hpe.com/v1beta2"
kind: SparkApplication
metadata:
  name: gpu-pyspark-cross-validator
  namespace: sampletenant
spec:
  sparkConf:
    # Note: If you are executing the application as a K8 user that MapR can verify,
#           you do not need to specify a spark.mapr.user.secret
    spark.mapr.user.secret: ${your secret}

    # Enabling RAPIDs plugin
    spark.plugins: "com.nvidia.spark.SQLPlugin"
    spark.rapids.sql.enabled: "true"

    # GPU allocation and discovery settings
    spark.task.resource.gpu.amount: "1"
    spark.executor.resource.gpu.amount: "1"
    spark.executor.resource.gpu.vendor: "nvidia.com"
    spark.executor.resource.gpu.discoveryScript: "/opt/mapr/spark/spark-3.2.0/examples/src/main/scripts/getGpusResources.sh"

  type: Scala
  sparkVersion: 3.2.0
  mode: cluster
  image: gcr.io/mapr-252711/spark-3.2.0:202202161825P150-gpu
  imagePullPolicy: Always
  mainApplicationFile: "maprfs:///${path to file}/cross_validator.py"
  restartPolicy:
    type: Never
  imagePullSecrets:
    - imagepull
  driver:
    cores: 1
    coreLimit: "1000m"
    memory: "512m"
    labels:
      version: 3.2.0
    # Note: You do not need to specify a serviceAccount
    #       it will be auto-generated referencing the pre-existing "hpe-<namespace>"
      serviceAccount: hpe-sampletenant
  executor:
    cores: 1
    coreLimit: "1000m"
    instances: 1
    memory: "2G"
    gpu:
      name: "nvidia.com/gpu"
      quantity: 1
    labels:
      version: 3.2.0
